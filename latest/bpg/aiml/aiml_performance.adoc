//!!NODE_ROOT <section>
[."topic"]
[[aiml-performance,aiml-performance.title]]
= AI/ML on EKS - Performance
:info_doctype: section
:imagesdir: images/
:info_title: Performance
:info_abstract: Performance
:info_titleabbrev: Performance
:authors: ["Leah Tucker"]
:date: 2025-05-30

== Application Scaling and Performance

=== Optimize Image Pull Performance
We strongly recommend optimizing container image pull performance for Amazon EKS clusters running AI/ML workloads. Using large, unoptimized base images or inefficient layer ordering can lead to slow pod startup times, increased resource consumption, and degraded inference latency. To address this, adopt small, lightweight base images with minimal dependencies, tailored to your workloads. You can also consider the AWS Deep Learning Containers (DLCs) which **** are pre-built container images that make it easier to run popular deep learning frameworks  (e.g., https://pytorch.org/[PyTorch] and https://www.tensorflow.org/[TensorFlow]). To learn more about building a custom image, see https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/deep-learning-containers-custom-images.html[Customize Deep Learning Containers]. When building custom images, consider lightweight base images and add only necessary libraries to keep images lean. Use multi-stage builds to reduce layer size and optimize layer ordering for efficient caching. For more details, see the https://docs.docker.com/develop/develop-images/dockerfile_best-practices/[Docker Best Practices for Building Images].

=== Reduce Container Startup Times by Preloading Container Images into Data Volumes
For machine learning workloads requiring low pod startup latency, such as real-time inference, we recommend preloading container images to minimize initialization delays. Large container images can slow pod startup, especially on nodes with limited bandwidth. In addition to using minimal base images, multi-stage builds, and lazy-loading techniques, consider the following approaches to preload images in Amazon EKS. In addition to using minimal base images, multi-stage builds, and lazy-loading techniques, consider the following options:

* **Pre-load images using EBS snapshots**: Take an Amazon Elastic Block Store (EBS) snapshot of cached container images and reuse this snapshot for EKS worker nodes. Though this adds additional operational activities it ensures images are prefetched locally upon node startup, reducing pod initialization time. See this https://aws.amazon.com/blogs/containers/reduce-container-startup-time-on-amazon-eks-with-bottlerocket-data-volume/[Reduce container startup time on Amazon EKS with Bottlerocket data volume] for more information using Karpenter and this https://aws-ia.github.io/terraform-aws-eks-blueprints/patterns/machine-learning/ml-container-cache/[EKS Terraform Blueprints] for managed node groups.
* **Pre-pull images into container runtime cache**: Pre-pull container images onto nodes using Kubernetes resources (e.g., DaemonSet or Deployment) to populate the nodeâ€™s container runtime cache. The container runtime cache is the local storage managed by the container runtime (e.g., https://containerd.io/[containerd]) where images are stored after being pulled from a registry. Pre-pulling ensures images are available locally, avoiding download delays during pod startup. This approach is useful when EBS snapshots are not preconfigured or when image pre-pulling is preferred. Test this approach in a staging environment to validate latency improvements. See the https://github.com/aws-samples/aws-do-eks/tree/main/Container-Root/eks/deployment/prepull[AWS Samples GitHub repository] for examples of pre-pulling images.
