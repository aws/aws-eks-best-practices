//!!NODE_ROOT <chapter>
[[aiml,aiml.title]]
= AI/ML on EKS - Introduction
:doctype: book
:sectnums:
:toc: left
:icons: font
:experimental:
:idprefix:
:idseparator: -
:sourcedir: .
:info_doctype: chapter
:info_title: Best Practices for Running AI/ML Workloads
:info_abstract: Best Practices for running AI/ML workloads on EKS
:info_titleabbrev: AI/ML on EKS
:imagesdir: images/
:authors: ["Leah Tucker"]
:date: 2025-05-30

Implementing best practices when running AI/ML workloads on EKS can ensure that those workloads are performant, cost-effective, resilient, and properly resourced.
Best practices for AI/ML on EKS are divided into the following general sections: Compute, Networking, Storage, Observability, and Performance.

== Feedback

This guide is being released on GitHub so as to collect direct feedback and suggestions from the broader EKS/Kubernetes community. If you have a best practice that you feel we ought to include in the guide, please file an issue or submit a PR in the GitHub repository. Our intention is to update the guide periodically as new features are added to the service or when a new best practice evolves.

include::ai_ml_compute.adoc[leveloffset=+1]

include::ai_ml_networking.adoc[leveloffset=+1]

include::ai_ml_storage.adoc[leveloffset=+1]

include::ai_ml_observability.adoc[leveloffset=+1]

include::ai_ml_performance.adoc[leveloffset=+1]
