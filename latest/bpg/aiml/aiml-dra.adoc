[.topic]
[#aiml-dra]
= Dynamic resource allocation for advanced GPU management
:info_titleabbrev: Dynamic resource allocation

https://kubernetes.io/docs/concepts/scheduling-eviction/dynamic-resource-allocation/#enabling-dynamic-resource-allocation[Dynamic
resource allocation (DRA)] represents a fundamental advancement in
Kubernetes GPU resource management. DRA moves beyond traditional device
plugin limitations to enable sophisticated GPU sharing, topology
awareness, and cross-node resource coordination. Available in Amazon EKS link:eks/latest/userguide/kubernetes-versions-standard.html#kubernetes-1-33[version 1.33,type="documentation"], DRA addresses critical challenges in AI/ML workloads by providing
the following:

* Fine-grained GPU allocation
* Advanced sharing mechanisms, such as Multi-Process service (MPS) and
Multi-Instance GPU (MIG)
* Support for next-generation hardware architectures, including NVIDIA
GB200 UltraClusters

Traditional GPU allocation treats GPUs as opaque integer resources,
creating significant under-utilization (often 30-40% in production
clusters). This occurs because workloads receive exclusive access to
entire GPUs even when requiring only fractional resources. DRA
transforms this model by introducing structured, declarative allocation
that provides the Kubernetes scheduler with complete visibility into
hardware characteristics and workload requirements. This enables
intelligent placement decisions and efficient resource sharing.

[#aiml-dra-advantages]
== Advantages of using DRA instead of NVIDIA device plugin

The NVIDIA device plugin (starting from version `0.12.0`) supports GPU
sharing mechanisms including time-slicing, MPS, and MIG. However,
architectural limitations exist that DRA addresses.

*NVIDIA device plugin limitations*

* *Static configuration:* GPU sharing configurations (time-slicing
replicas and MPS settings) require pre-configuration cluster-wide
through `ConfigMaps`. This makes providing different sharing strategies
for different workloads difficult.
* *Limited granular selection:* While the device plugin exposes GPU
characteristics through node labels, workloads cannot dynamically
request specific GPU configurations (memory size and compute
capabilities) as part of the scheduling decision.
* *No cross-node resource coordination:* Cannot manage distributed GPU
resources across multiple nodes or express complex topology requirements
like NVLink domains for systems like NVIDIA GB200.
* *Scheduler constraints:* The Kubernetes scheduler treats GPU resources
as opaque integers, limiting its ability to make topology-aware
decisions or handle complex resource dependencies.
* *Configuration complexity:* Setting up different sharing strategies
requires multiple `ConfigMaps` and careful node labeling, creating
operational complexity.

*Solutions with DRA*

* *Dynamic resource selection:* DRA allows workloads to specify detailed
requirements (GPU memory, driver versions, and specific attributes) at
request time through `resourceclaims`. This enables more flexible
resource matching.
* *Topology awareness:* Through structured parameters and device
selectors, DRA handles complex requirements like cross-node GPU
communication and memory-coherent interconnects.
* *Cross-node resource management:* `computeDomains` enable coordination
of distributed GPU resources across multiple nodes, critical for systems
like GB200 with IMEX channels.
* *Workload-specific configuration:* Each `ResourceClaim` specifies
different sharing strategies and configurations, allowing fine-grained
control per workload rather than cluster-wide settings.
* *Enhanced scheduler integration:* DRA provides the scheduler with
detailed device information and enables more intelligent placement
decisions based on hardware topology and resource characteristics.

Important: DRA does not replace the NVIDIA device plugin entirely. The
NVIDIA DRA driver works alongside the device plugin to provide enhanced
capabilities. The device plugin continues to handle basic GPU discovery
and management, while DRA adds advanced allocation and scheduling
features.

[#aiml-dra-instances]
== Instances supported by DRA and their features

DRA support varies by Amazon EC2 instance family and GPU architecture,
as shown in the following table.

[%header, cols="1,1,1,1,1,1,2"]
|===
|Instance family
|GPU type
|Time-slicing
|MIG support
|MPS support
|IMEX support
|Use cases

|G5
|NVIDIA A10G
|Yes
|No
|Yes
|No
|Inference and graphics workloads

|G6
|NVIDIA L4
|Yes
|No
|Yes
|No
|AI inference and video processing

|G6e
|NVIDIA L40S
|Yes
|No
|Yes
|No
|Training, inference, and graphics

|P4d/P4de
|NVIDIA A100
|Yes
|Yes
|Yes
|No
|Large-scale training and HPC

|P5
|NVIDIA H100
|Yes
|Yes
|Yes
|No
|Foundation model training

|P6
|NVIDIA B200
|Yes
|Yes
|Yes
|No
|Billion or trillion-parameter models, distributed training, and inference

|P6e
|NVIDIA GB200
|Yes
|Yes
|Yes
|Yes
|Billion or trillion-parameter models, distributed training, and inference
|===

The following are descriptions of each feature in the table:

* *Time-slicing*: Allows multiple workloads to share GPU compute
resources over time.
* *Multi-Instance GPU (MIG)*: Hardware-level partitioning that creates
isolated GPU instances.
* *Multi-Process service (MPS)*: Enables concurrent execution of
multiple CUDA processes on a single GPU.
* *Internode Memory Exchange (IMEX)*: Memory-coherent communication
across nodes for GB200 UltraClusters.

[#aiml-dra-additional-resources]
== Additional resources

For more information about Kubernetes DRA and NVIDIA DRA drivers, see
the following resources on GitHub:

* Kubernetes
https://github.com/kubernetes/dynamic-resource-allocation[dynamic-resource-allocation]
* https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/3063-dynamic-resource-allocation[Kubernetes
enhancement proposal for DRA]
* https://github.com/NVIDIA/k8s-dra-driver-gpu[NVIDIA DRA Driver for
GPUs]
* https://github.com/NVIDIA/k8s-dra-driver-gpu/tree/main/demo/specs/quickstart[NVIDIA
DRA examples and quickstart]

include::aiml-dra-setup.adoc[leveloffset=+1]

include::aiml-dra-workload.adoc[leveloffset=+1]

include::aiml-dra-optimization.adoc[leveloffset=+1]
